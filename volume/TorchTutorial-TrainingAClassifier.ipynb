{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_init():\n",
    "    device_id = 1\n",
    "    torch.cuda.set_device(device_id)\n",
    "    \n",
    "    # Sanity checks\n",
    "    assert torch.cuda.current_device() == 1, 'Using wrong GPU'\n",
    "    assert torch.cuda.device_count() == 2, 'Cannot find both GPUs'\n",
    "    assert torch.cuda.get_device_name(0) == 'GeForce RTX 2080 Ti', 'Wrong GPU name'\n",
    "    assert torch.cuda.is_available() == True, 'GPU not available'\n",
    "    return torch.device('cuda', device_id)\n",
    "    \n",
    "device = pytorch_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a dataset class that is compatible with the torch.utils.data.DataLoader thing you should subclass **VisionDataset** from *torchvision.datasets.vision.VisionDataset* and implement *__getitem__* and *__len__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Returns a Dataset object\n",
    "trainset = torchvision.datasets.CIFAR10(root='data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "# Equivalent to Tensorflow generators, \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=10)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=10)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show an image\n",
    "def imshow(img, labels: list):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(labels)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "# show images\n",
    "# imshow(torchvision.utils.make_grid(images), str(labels.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # in_channels: Input channels (3 since RGB)\n",
    "        # out_channels: Number of filters basically\n",
    "        # kernel_size: u know what it is\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        # TODO: Figure out why 16*5*5\n",
    "        self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Like reshape\n",
    "        x = x.view(-1 , 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# .to method can be use to cast to many different things, and is used to \"cast\" tensors to GPU \n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1/5: 100%|##########| 12500/12500 [00:32<00:00, 382.30 batches/s, loss=1.69]\n",
      " Epoch 2/5: 100%|##########| 12500/12500 [00:32<00:00, 385.52 batches/s, loss=1.33]\n",
      " Epoch 3/5: 100%|##########| 12500/12500 [00:32<00:00, 384.13 batches/s, loss=1.19]\n",
      " Epoch 4/5: 100%|##########| 12500/12500 [00:32<00:00, 384.14 batches/s, loss=1.09]\n",
      " Epoch 5/5: 100%|##########| 12500/12500 [00:32<00:00, 384.83 batches/s, loss=1.02]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    bar = tqdm(\n",
    "        iterable=enumerate(trainloader, 0), \n",
    "        total=len(trainloader), \n",
    "        unit=' batches',\n",
    "        desc=f' Epoch {epoch+1}/{n_epochs}',\n",
    "        file=sys.stdout,\n",
    "        ascii=True,\n",
    "        position=0\n",
    "    )\n",
    "    \n",
    "    # Loop through batches\n",
    "    for i, data in bar:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                \n",
    "        # Zero parameter gradients since PyTorch will just accumulate the gradient\n",
    "        # vectors while it trains (in order to get the \"mean\" direction to move in\n",
    "        # the parameter space). Also doing it this way minimizes memory allocation \n",
    "        # etc, probably. \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() # Computes gradients \n",
    "        optimizer.step() # Do a gradient step\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        bar.set_postfix({'loss':running_loss / (i+1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'models/cifar_net.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
