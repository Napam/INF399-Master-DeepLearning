{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generic, Optional, Tuple, List, Callable, Iterable, Mapping\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.models import resnet50\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import utils\n",
    "from utils import debugt, debugs, debug\n",
    "\n",
    "torch.hub.set_dir('torch_cache')\n",
    "import fishdetr_batchboy as detr\n",
    "import contextlib\n",
    "from generators import TorchStereoDataset\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import sys\n",
    "sys.path.append('./detr_custom/')\n",
    "from models.matcher import HungarianMatcher\n",
    "from models.detr import SetCriterion\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugt = utils.reloader(debugt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.seed_everything(42069)\n",
    "\n",
    "try:\n",
    "    device = utils.pytorch_init_janus_gpu()\n",
    "    print(f'Using device: {device} ({torch.cuda.get_device_name()})')\n",
    "    print(utils.get_cuda_status(device))\n",
    "except AssertionError as e:\n",
    "    print('GPU could not initialize, got error:', e)\n",
    "    device = torch.device('cpu')\n",
    "    print('Device is set to CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/blendervol/leftright_left_data'\n",
    "TABLE = 'bboxes_std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traingen = TorchStereoDataset(DATA_DIR, TABLE, shuffle=False, imgnrs=range(8,8+32))\n",
    "loader1 = torch.utils.data.DataLoader(\n",
    "    traingen,\n",
    "    batch_size=32,\n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "\n",
    "loader2 = torch.utils.data.DataLoader(\n",
    "    traingen,\n",
    "    batch_size=32,\n",
    "    collate_fn=detr.collate\n",
    ")\n",
    "\n",
    "X1, y1 = next(iter(loader1))\n",
    "X2, y2 = next(iter(loader2))\n",
    "\n",
    "X1 = list(X1)\n",
    "X2 = list(X2)\n",
    "y1 = detr.label_handler(y1, device)\n",
    "y2 = detr.label_handler(y2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = T.Compose([T.Resize(800), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "X2[0] = trans(X2[0]).to(device)\n",
    "X2[1] = trans(X2[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.reloader(detr)\n",
    "model = detr.FishDETR().to(device)\n",
    "model.encoder = model.encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sanity_check_singles(X: List[Tuple[torch.tensor, torch.tensor]], model, device=None):\n",
    "    X: Tuple[Tuple[torch.Tensor, torch.Tensor]]\n",
    "    output = torch.cat([model(l.to(device)) for l, r in X], axis=0)\n",
    "    return output\n",
    "\n",
    "@torch.no_grad()\n",
    "def sanity_check_batch(X: Tuple[torch.Tensor, torch.Tensor], model: nn.Module, device: torch.device=None):    \n",
    "    X: Tuple[torch.Tensor, torch.Tensor]\n",
    "    output = model(X[0].to(device))\n",
    "    return output\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     output1 = sanity_check_singles(X1, model.encoder, device)\n",
    "#     output2 = sanity_check_batch(X2, model.encoder, device)\n",
    "#     debugs(output1)\n",
    "#     debugs(output2)\n",
    "#     print()\n",
    "#     debug(output1[0])\n",
    "#     debug(output2[0])\n",
    "#     print()\n",
    "#     debug(torch.allclose(output1, output2))\n",
    "#     diff = output1 - output2\n",
    "#     debug(diff.shape)\n",
    "#     debug(abs(diff).max())\n",
    "#     debug(abs(diff).mean())\n",
    "#     debug(abs(diff).std())\n",
    "#     fig = px.histogram(diff.flatten(), nbins=50)\n",
    "#     fig.show()\n",
    "#     fig = px.histogram(abs(diff.cpu().numpy().ravel()[::16]), nbins=200)\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = [None]*2\n",
    "with torch.no_grad():\n",
    "    H[0] = model.encoder(X2[0].to(device))\n",
    "    H[1] = model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugs(X2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@utils.interruptable\n",
    "def train_head(model, epochs: int=1):        \n",
    "    weight_dict = {'loss_ce': 1, 'loss_bbox': 1 , 'loss_giou': 1}\n",
    "    losses = ['labels', 'boxes', 'cardinality']\n",
    "    matcher = HungarianMatcher()\n",
    "    criterion = SetCriterion(6, matcher, weight_dict, 0.5, losses).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.decoder.parameters(), lr=1e-4)\n",
    "    \n",
    "    model.decoder.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    running_train_loss = 0.0\n",
    "    for epoch in range(1,epochs+1):\n",
    "        output = model(X2)\n",
    "        loss_dict = criterion(output, y2)\n",
    "        weight_dict = criterion.weight_dict\n",
    "        losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward() # Computes gradients\n",
    "        optimizer.step() # Do a gradient step\n",
    "        \n",
    "        running_train_loss += losses.item()\n",
    "        train_loss = running_train_loss / (epoch)\n",
    "        if not epoch % 20: print(losses.item())\n",
    "            \n",
    "    return output\n",
    "\n",
    "output = train_head(model, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_model(model, 'batch_overfit.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.reloader(detr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def box_cxcywh_to_xyxy(x: torch.Tensor):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "\n",
    "def plot_results(img, classes: Iterable, boxes: Iterable, classmap: Optional[Mapping[int, str]]=None, ax: Optional=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(16,10))\n",
    "        \n",
    "    img = np.array(img)\n",
    "    ax.imshow(img.clip(0,1))\n",
    "    \n",
    "    if len(boxes) != 0:\n",
    "        h, w = img.shape[:2]\n",
    "        boxes = box_cxcywh_to_xyxy(boxes)\n",
    "        boxes[:,[0,2]] *= w\n",
    "        boxes[:,[1,3]] *= h\n",
    "        \n",
    "        for cls, (xmin, ymin, xmax, ymax) in zip(classes, boxes):\n",
    "            ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                       fill=False, color='cyan', linewidth=3))\n",
    "            try:\n",
    "                strcls = classmap[int(cls)]\n",
    "            except:\n",
    "                strcls = str(int(cls))\n",
    "                    \n",
    "            ax.text(xmin, ymin, strcls, fontsize=11, bbox=dict(facecolor='cyan', alpha=0.9))\n",
    "    \n",
    "    if ax is None:\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    return ax\n",
    "\n",
    "    \n",
    "def eval_model(model, img: torch.Tensor, classmap: Optional[Mapping[int, str]]=None, ax: Optional=None):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        output = model((img[0].to(device), img[1].to(device)))\n",
    "        \n",
    "        boxes = output['pred_boxes'][0]\n",
    "        logits = output['pred_logits'][0]\n",
    "        \n",
    "        logits_, boxes_ = detr.postprocess(logits, boxes)\n",
    "        \n",
    "        plot_results(img[0][0].cpu().numpy().transpose((1,2,0)), logits_, boxes_, classmap, ax=ax)\n",
    "        \n",
    "        \n",
    "def eval_compare_model(model: nn.Module, gen: Iterable, index: int=0, classmap: Optional[Mapping[int, str]]=None):\n",
    "    x, y = gen[index]\n",
    "    fig, axes = plt.subplots(1,2,figsize=(15,7))\n",
    "    eval_model(model, detr.img_handler([x])[0], classmap, axes[0])\n",
    "    plot_results(x[0][0].cpu().numpy().transpose((1,2,0)), y['labels'], y['boxes'], classmap, axes[1])\n",
    "    axes[0].set_title('Predicted')\n",
    "    axes[1].set_title('Real')\n",
    "\n",
    "num2name = eval(open(os.path.join(DATA_DIR,\"metadata.txt\"), 'r').read())\n",
    "for i in range(32):\n",
    "    eval_compare_model(model, traingen, index=i, classmap=num2name)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
