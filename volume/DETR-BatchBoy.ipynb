{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generic, Optional, Tuple, List, Callable, Iterable, Mapping\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.models import resnet50\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import utils\n",
    "from utils import debugt, debugs, debug\n",
    "\n",
    "torch.hub.set_dir('torch_cache')\n",
    "import fishdetr_batchboy as detr\n",
    "import contextlib\n",
    "from generators import TorchStereoDataset\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import sys\n",
    "sys.path.append('./detr_custom/')\n",
    "from models.matcher import HungarianMatcher\n",
    "from models.detr import SetCriterion\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugt = utils.reloader(debugt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.seed_everything(42069)\n",
    "\n",
    "try:\n",
    "    device = utils.pytorch_init_janus_gpu()\n",
    "    print(f'Using device: {device} ({torch.cuda.get_device_name()})')\n",
    "    print(utils.get_cuda_status(device))\n",
    "except AssertionError as e:\n",
    "    print('GPU could not initialize, got error:', e)\n",
    "    device = torch.device('cpu')\n",
    "    print('Device is set to CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/blendervol/leftright_left_data'\n",
    "TABLE = 'bboxes_std'\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utils.reloader(detr)\n",
    "\n",
    "traingen = TorchStereoDataset(DATA_DIR, TABLE, shuffle=False, imgnrs=range(32,32+BATCH_SIZE))\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    traingen,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=detr.collate\n",
    ")\n",
    "\n",
    "X, y = next(iter(loader))\n",
    "X = detr.img_handler(X, device)\n",
    "y = detr.label_handler(y, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;2m(1, <module>)\u001b[0m \u001b[2mX[0]:\u001b[0m torch.Size([4, 3, 416, 416])\n"
     ]
    }
   ],
   "source": [
    "debugs(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder successfully loaded with pretrained weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FishDETR(\n",
       "  (encoder): Encoder(\n",
       "    (backbone): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "    (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (transformer): Transformer(\n",
       "      (encoder): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0, inplace=False)\n",
       "            (dropout2): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0, inplace=False)\n",
       "            (dropout2): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0, inplace=False)\n",
       "            (dropout2): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0, inplace=False)\n",
       "            (dropout2): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0, inplace=False)\n",
       "            (dropout2): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0, inplace=False)\n",
       "            (dropout2): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): TransformerDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0, inplace=False)\n",
       "            (dropout2): Dropout(p=0, inplace=False)\n",
       "            (dropout3): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (1): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0, inplace=False)\n",
       "            (dropout2): Dropout(p=0, inplace=False)\n",
       "            (dropout3): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (2): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0, inplace=False)\n",
       "            (dropout2): Dropout(p=0, inplace=False)\n",
       "            (dropout3): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (3): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0, inplace=False)\n",
       "            (dropout2): Dropout(p=0, inplace=False)\n",
       "            (dropout3): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (4): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0, inplace=False)\n",
       "            (dropout2): Dropout(p=0, inplace=False)\n",
       "            (dropout3): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "          (5): TransformerDecoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (multihead_attn): MultiheadAttention(\n",
       "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0, inplace=False)\n",
       "            (dropout2): Dropout(p=0, inplace=False)\n",
       "            (dropout3): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (block1): DecoderBlock(\n",
       "      (conv1): Conv2d(2, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): DecoderBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): DecoderBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): DecoderBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (linear_pre_class): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (linear_pre_bbox): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (linear_class): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Linear(in_features=512, out_features=7, bias=True)\n",
       "    )\n",
       "    (linear_bbox): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Linear(in_features=512, out_features=4, bias=True)\n",
       "      (5): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.reloader(detr)\n",
    "def set_momentum(x):\n",
    "    if isinstance(x, nn.BatchNorm2d):\n",
    "        x.requires_grad = False\n",
    "model = detr.FishDETR(freeze_encoder=False).to(device)\n",
    "model.apply(set_momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8805627822875977\n",
      "1.9677512645721436\n",
      "1.6017076969146729\n",
      "1.1915345191955566\n",
      "0.9605687856674194\n",
      "1.1059885025024414\n",
      "0.9821648597717285\n",
      "1.0160853862762451\n",
      "0.9224207401275635\n",
      "0.8833960294723511\n",
      "0.7011101245880127\n",
      "0.7258255481719971\n",
      "0.7441396713256836\n",
      "0.7199459671974182\n",
      "0.6247668862342834\n",
      "0.7448043823242188\n",
      "0.7159554958343506\n",
      "0.6626294851303101\n",
      "0.5454171895980835\n",
      "0.5122224688529968\n",
      "0.5177566409111023\n",
      "0.4513455629348755\n",
      "0.3521854877471924\n",
      "0.30806422233581543\n",
      "0.32931283116340637\n",
      "0.2902510464191437\n",
      "0.30373650789260864\n",
      "0.2489105761051178\n",
      "0.18112772703170776\n",
      "0.21118204295635223\n",
      "0.2594859302043915\n",
      "0.20510873198509216\n",
      "0.14866749942302704\n",
      "0.11886449158191681\n",
      "0.15167495608329773\n",
      "0.15043683350086212\n",
      "0.1566968560218811\n",
      "0.11991892009973526\n",
      "0.1468207687139511\n",
      "0.13623403012752533\n",
      "0.10654141753911972\n",
      "0.13795092701911926\n",
      "0.10552157461643219\n",
      "0.10083362460136414\n",
      "0.11372469365596771\n",
      "0.1136302798986435\n",
      "0.11676258593797684\n",
      "0.1376131772994995\n",
      "0.11060204356908798\n",
      "0.1240442544221878\n",
      "0.13285313546657562\n",
      "0.09639390558004379\n",
      "0.07282552123069763\n",
      "0.11526000499725342\n",
      "0.07753235846757889\n",
      "0.08087601512670517\n",
      "0.10304145514965057\n",
      "0.08352631330490112\n",
      "0.0888071209192276\n",
      "0.07774633169174194\n",
      "0.08118321001529694\n",
      "0.08904315531253815\n",
      "0.0863441675901413\n",
      "0.09921848028898239\n",
      "0.09287063777446747\n",
      "0.08414781093597412\n",
      "0.07087698578834534\n",
      "0.11133968085050583\n",
      "0.08526234328746796\n",
      "0.11420004069805145\n",
      "0.08599124103784561\n",
      "0.1158311665058136\n",
      "0.08869700878858566\n",
      "0.06351042538881302\n",
      "0.08931756019592285\n",
      "0.09886575490236282\n",
      "0.12541624903678894\n",
      "0.11271941661834717\n",
      "0.08630184829235077\n",
      "0.07541754841804504\n"
     ]
    }
   ],
   "source": [
    "@utils.interruptable\n",
    "def train(model, X, y, epochs: int=1):        \n",
    "    weight_dict = {'loss_ce': 1, 'loss_bbox': 1 , 'loss_giou': 1}\n",
    "    losses = ['labels', 'boxes', 'cardinality']\n",
    "    matcher = HungarianMatcher()\n",
    "    criterion = SetCriterion(6, matcher, weight_dict, 0.5, losses).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    model.train()\n",
    "    def bn_eval(x):\n",
    "        if isinstance(x, nn.BatchNorm2d):\n",
    "            x.eval()\n",
    "    criterion.train()\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "        output, loss = model.train_on_batch(X, y, criterion, optimizer)\n",
    "        loss: torch.Tensor\n",
    "        if not epoch % 10:\n",
    "            print(loss.item())\n",
    "    return output\n",
    "\n",
    "output = train(model, X, y, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_model(model, 'batch_overfit.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.reloader(detr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def bobo(model, X: Tuple[torch.Tensor, torch.Tensor], output):\n",
    "    model = model.eval()\n",
    "    X = X.copy()\n",
    "    X[0], X[1] = X[0][:1], X[1][:1]\n",
    "    output = model(X)\n",
    "    boxess = output['pred_boxes']\n",
    "    logitss = output['pred_logits']\n",
    "    for left, right, boxes, logits in zip(X[0], X[1], boxess, logitss):\n",
    "        logits_, boxes_ = detr.postprocess(logits, boxes)\n",
    "        plot_results(left.cpu().permute((1,2,0)), logits_, boxes_, num2name) \n",
    "    \n",
    "bobo(model, X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c85a9010cf30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0meval_compare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraingen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum2name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c85a9010cf30>\u001b[0m in \u001b[0;36meval_compare_model\u001b[0;34m(model, gen, index, classmap)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/fishdetr_batchboy.py\u001b[0m in \u001b[0;36mimg_handler\u001b[0;34m(images, device)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mEach\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     '''\n\u001b[0;32m--> 341\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def box_cxcywh_to_xyxy(x: torch.Tensor):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "\n",
    "def plot_results(img, classes: Iterable, boxes: Iterable, classmap: Optional[Mapping[int, str]]=None, ax: Optional=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(16,10))\n",
    "        \n",
    "    img = np.array(img)\n",
    "    ax.imshow(img.clip(0,1))\n",
    "    \n",
    "    if len(boxes) != 0:\n",
    "        h, w = img.shape[:2]\n",
    "        boxes = box_cxcywh_to_xyxy(boxes)\n",
    "        boxes[:,[0,2]] *= w\n",
    "        boxes[:,[1,3]] *= h\n",
    "        \n",
    "        for cls, (xmin, ymin, xmax, ymax) in zip(classes, boxes):\n",
    "            ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                       fill=False, color='cyan', linewidth=3))\n",
    "            try:\n",
    "                strcls = classmap[int(cls)]\n",
    "            except:\n",
    "                strcls = str(int(cls))\n",
    "                    \n",
    "            ax.text(xmin, ymin, strcls, fontsize=11, bbox=dict(facecolor='cyan', alpha=0.9))\n",
    "    \n",
    "    if ax is None:\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    return ax\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, X: Tuple[torch.Tensor, torch.Tensor], classmap: Optional[Mapping[int, str]]=None, ax: Optional=None):\n",
    "    model.eval()\n",
    "    \n",
    "    output = model(X)\n",
    "    boxes = output['pred_boxes'][0]\n",
    "    logits = output['pred_logits'][0]\n",
    "\n",
    "    logits_, boxes_ = detr.postprocess(logits, boxes, thresh=0.1)\n",
    "\n",
    "    plot_results(img[0][0].cpu().numpy().transpose((1,2,0)), logits_, boxes_, classmap, ax=ax)\n",
    "        \n",
    "        \n",
    "def eval_compare_model(model: nn.Module, gen: Iterable, index: int=0, classmap: Optional[Mapping[int, str]]=None):\n",
    "    x, y = gen[index]\n",
    "    fig, axes = plt.subplots(1,2,figsize=(15,7))\n",
    "    eval_model(model, detr.img_handler([x])[0], classmap, axes[0])\n",
    "    plot_results(x[0][0].cpu().numpy().transpose((1,2,0)), y['labels'], y['boxes'], classmap, axes[1])\n",
    "    axes[0].set_title('Predicted')\n",
    "    axes[1].set_title('Real')\n",
    "    \n",
    "\n",
    "num2name = eval(open(os.path.join(DATA_DIR,\"metadata.txt\"), 'r').read())\n",
    "model.eval()\n",
    "for i in range(BATCH_SIZE):\n",
    "    eval_compare_model(model, traingen, index=i, classmap=num2name)\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
