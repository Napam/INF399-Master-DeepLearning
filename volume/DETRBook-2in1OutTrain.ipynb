{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generic, Optional, Tuple, List, Callable, Iterable, Mapping\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.models import resnet50\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import utils\n",
    "from utils import debugt, debugs, debug\n",
    "\n",
    "import fishdetr_batchboy as detr\n",
    "from generators import TorchStereoDataset\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./detr_custom/')\n",
    "from models.matcher import HungarianMatcher\n",
    "from models.detr import SetCriterion\n",
    "import os\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1 (GeForce RTX 2080 Ti)\n",
      "GeForce RTX 2080 Ti \n",
      "Memory usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached   : 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "seed = 42069\n",
    "utils.seed_everything(seed)\n",
    "\n",
    "try:\n",
    "    device = utils.pytorch_init_janus_gpu()\n",
    "    print(f'Using device: {device} ({torch.cuda.get_device_name()})')\n",
    "    print(utils.get_cuda_status(device))\n",
    "except AssertionError as e:\n",
    "    print('GPU could not initialize, got error:', e)\n",
    "    device = torch.device('cpu')\n",
    "    print('Device is set to CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_CACHE_DIR = 'torch_cache'\n",
    "DATASET_DIR = '/mnt/blendervol/objdet_std_data'\n",
    "DATASET_DIR = '/mnt/blendervol/leftright_left_data'\n",
    "TABLE = 'bboxes_std'\n",
    "WEIGHTS_DIR = 'fish_statedicts'\n",
    "torch.hub.set_dir(TORCH_CACHE_DIR)\n",
    "num2name = eval(open(os.path.join(DATASET_DIR,\"metadata.txt\"), 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_model(context: dict, traintqdminfo: dict) -> dict:\n",
    "    model = context['model']\n",
    "    criterion = context['criterion']\n",
    "\n",
    "    running_val_loss = 0.0\n",
    "    # valbar will disappear after it is done since leave=False\n",
    "    valbar = tqdm(\n",
    "        iterable=enumerate(context['valloader'], 0), \n",
    "        total=len(context['valloader']), \n",
    "        unit=' batches',\n",
    "        desc=f' Validating',\n",
    "        ascii=True,\n",
    "        position=0,\n",
    "        leave=False\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "\n",
    "    # Loop through val batches\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in valbar:\n",
    "            X, y = detr.preprocess(images, labels, context['device'])\n",
    "\n",
    "            output = model(X)\n",
    "            loss_dict = criterion(output, y)\n",
    "            weight_dict = criterion.weight_dict\n",
    "            losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "            # print statistics\n",
    "            running_val_loss += losses.item()\n",
    "            val_loss = running_val_loss / (i+1)\n",
    "            valtqdminfo = {**traintqdminfo, 'val loss':val_loss}\n",
    "            valbar.set_postfix(valtqdminfo)\n",
    "            \n",
    "    return valtqdminfo\n",
    "\n",
    "\n",
    "def _train_model(context: dict, epoch: int, n_epochs: int, leave_tqdm: bool) -> Tuple[Iterable, dict]:\n",
    "    model = context['model']\n",
    "    criterion = context['criterion']\n",
    "    \n",
    "    running_train_loss = 0.0\n",
    "    trainbar = tqdm(\n",
    "        iterable=enumerate(context['trainloader'], 0),\n",
    "        total=len(context['trainloader']),\n",
    "        unit=' batches',\n",
    "        desc=f' Epoch {epoch+1}/{n_epochs}',\n",
    "        ascii=True,\n",
    "        position=0,\n",
    "        leave=leave_tqdm\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "\n",
    "    # Loop through train batches\n",
    "    for i, (images, labels) in trainbar:\n",
    "        X, y = detr.preprocess(images, labels, context['device'])\n",
    "\n",
    "        output = model(X)\n",
    "        loss_dict = criterion(output, y)\n",
    "        weight_dict = criterion.weight_dict\n",
    "        losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "        # Zero parameter gradients since PyTorch will just accumulate the gradient\n",
    "        # vectors while it trains (in order to get the \"mean\" direction to move in\n",
    "        # the parameter space). Also doing it this way minimizes memory allocation\n",
    "        # etc, probably.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        losses.backward() # Computes gradients\n",
    "        optimizer.step() # Do a gradient step\n",
    "\n",
    "        # print statistics\n",
    "        running_train_loss += losses.item()\n",
    "        train_loss = running_train_loss / (i+1)\n",
    "        traintqdminfo = {'train loss':train_loss}\n",
    "        trainbar.set_postfix(traintqdminfo)\n",
    "    \n",
    "    return trainbar, traintqdminfo\n",
    "\n",
    "\n",
    "@utils.interruptable\n",
    "def train_model(\n",
    "        trainloader: DataLoader, \n",
    "        valloader: DataLoader, \n",
    "        model: nn.Module, \n",
    "        criterion, \n",
    "        optimizer, \n",
    "        n_epochs: int, \n",
    "        device: torch.device, \n",
    "        validate: bool = True,\n",
    "        save_best: bool = True\n",
    "    ):\n",
    "    \n",
    "    # for convenience\n",
    "    context = {\n",
    "        'trainloader':trainloader,\n",
    "        'valloader':valloader,\n",
    "        'model':model,\n",
    "        'criterion':criterion,\n",
    "        'optimizer':optimizer,\n",
    "        'device':device\n",
    "    }\n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        trainbar, traintqdminfo = _train_model(context, epoch, n_epochs, not validate)\n",
    "            \n",
    "        if validate:\n",
    "            valtqdminfo = _validate_model(context, traintqdminfo)\n",
    "        \n",
    "            # Extra dirty tqdm hack hehe\n",
    "            # _validate_model will create its own tqdm bar that will replace the bar\n",
    "            # from _train_model, but will clear itself afterwards\n",
    "            # the code below reactivates the previous train bar\n",
    "            trainbar.disable = False\n",
    "            trainbar.set_postfix({**traintqdminfo, **valtqdminfo})\n",
    "            trainbar.disable = True\n",
    "            print(file=sys.stderr) # for newline\n",
    "        \n",
    "            # Save best models\n",
    "            if save_best:\n",
    "                if valtqdminfo['val loss'] < best_val_loss:\n",
    "                    best_val_loss = valtqdminfo['val loss']\n",
    "                    isodatenow = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "                    daydir = datetime.today().strftime(\"weights_%Y-%m-%d\")\n",
    "                    filename = (\n",
    "                        f'detr_statedicts_epoch{epoch+1}'\n",
    "                        f'_train{traintqdminfo[\"train loss\"]:.4f}_val{best_val_loss:.4f}'\n",
    "                        f'_{isodatenow}.pth'\n",
    "                    )\n",
    "                    filepath = os.path.join(WEIGHTS_DIR, daydir, filename)\n",
    "\n",
    "                    save_model(\n",
    "                        obj={\n",
    "                            'model':model.state_dict(),\n",
    "                            'optimizer':optimizer.state_dict(),\n",
    "                            'criterion':criterion.state_dict(),\n",
    "                        },\n",
    "                        f = filepath\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder successfully loaded with pretrained weights\n"
     ]
    }
   ],
   "source": [
    "model = detr.FishDETR(freeze_encoder=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_con = sqlite3.connect(f'file:{os.path.join(DATASET_DIR,\"bboxes.db\")}?mode=ro', uri=True)\n",
    "n_data = pd.read_sql_query('SELECT COUNT(DISTINCT(imgnr)) FROM bboxes_std', db_con).values[0][0]\n",
    "\n",
    "TRAIN_RANGE = (0, int(3/4*n_data))\n",
    "VAL_RANGE = (int(3/4*n_data), n_data)\n",
    "\n",
    "TRAIN_RANGE = (0, 1024)\n",
    "VAL_RANGE = (1024, 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = {'loss_ce': 1, 'loss_bbox': 1 , 'loss_giou': 1}\n",
    "losses = ['labels', 'boxes', 'cardinality']\n",
    "matcher = HungarianMatcher()\n",
    "criterion = SetCriterion(6, matcher, weight_dict, eos_coef = 0.5, losses=losses)\n",
    "criterion = criterion.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "traingen = TorchStereoDataset(DATASET_DIR, TABLE, 1, shuffle=True, imgnrs=range(*TRAIN_RANGE))\n",
    "valgen = TorchStereoDataset(DATASET_DIR, TABLE, 1, shuffle=False, imgnrs=range(*VAL_RANGE))\n",
    "\n",
    "BATCH_SIZE = 6\n",
    "trainloader = DataLoader(\n",
    "    dataset = traingen,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    collate_fn = detr.collate,\n",
    ")\n",
    "\n",
    "valloader = DataLoader(\n",
    "    dataset = valgen,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    collate_fn = detr.collate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Epoch 1/20:  87%|########6 | 148/171 [01:03<00:09,  2.41 batches/s, train loss=1.85]"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    trainloader,\n",
    "    valloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    n_epochs=20,\n",
    "    device=device,\n",
    "    save_best=False,\n",
    "    validate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
