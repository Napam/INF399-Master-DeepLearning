{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import torchvision.transforms as T\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from skimage import io\n",
    "\n",
    "################# DETR FUCNTIONS FOR LOSS######################## \n",
    "import sys\n",
    "sys.path.append('./detr_custom/')\n",
    "\n",
    "from models.matcher import HungarianMatcher\n",
    "from models.detr import SetCriterion\n",
    "#################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Glob\n",
    "from glob import glob\n",
    "\n",
    "from typing import Iterable, Sequence, List, Tuple, Dict, Optional, Any\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from generators import BlenderStandardDataset\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "from utils import debugs, debug, debugt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_CACHE_DIR = 'torch_cache'\n",
    "DATASET_DIR = '/mnt/blendervol/objdet_std_data'\n",
    "SQL_TABLE = 'bboxes_std'\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import generators\n",
    "reload(generators)\n",
    "from generators import BlenderStandardDataset\n",
    "\n",
    "datagen = BlenderStandardDataset(DATASET_DIR, SQL_TABLE, BATCH_SIZE, shuffle=False)\n",
    "X, y = datagen[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(data: Iterable[Tuple[np.ndarray, Any]]):\n",
    "    denominator = 0\n",
    "    mean = np.zeros(3)\n",
    "    data = [data]\n",
    "    for imgbatch, __ in tqdm(data, total=len(data), disable=True):\n",
    "        imgbatch = np.array(imgbatch)\n",
    "        n = len(imgbatch)\n",
    "        mean = np.average((mean, imgbatch.mean((0,1,2))), 0, weights=(denominator, n))\n",
    "        denominator += n\n",
    "        \n",
    "    return mean\n",
    "\n",
    "def calc_var(data: Iterable[Tuple[np.ndarray, Any]], mean: np.ndarray):\n",
    "    denominator = 0\n",
    "    var = np.zeros_like(mean)\n",
    "    for imgbatch, __ in tqdm(data, total=len(data)):\n",
    "        imgbatch = np.array(imgbatch)\n",
    "        n = len(imgbatch)\n",
    "        \n",
    "        batchvar = ((imgbatch - mean)**2).mean((0,1,2))\n",
    "        var = np.average((var, batchvar), axis=0, weights=(denominator, n))\n",
    "        denominator += n\n",
    "    return var\n",
    "    \n",
    "def calc_stats(data: Iterable):\n",
    "    print('Calculating mean:')\n",
    "    mean = calc_mean(data)\n",
    "    print('Calculating variance')\n",
    "    var = calc_var(data, mean)\n",
    "    print(f'Mean: {mean}')\n",
    "    print(f'Variance: {var}')\n",
    "    print(f'Std: {np.sqrt(var)}')\n",
    "    \n",
    "    return mean, var\n",
    "\n",
    "# m, v = calc_stats(datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testmp(x):\n",
    "    return x@x\n",
    "\n",
    "def genboi():\n",
    "    for i in range(10000):\n",
    "        yield np.random.randn(128,128)\n",
    "\n",
    "with mp.Pool(20) as pool:\n",
    "    bish = pool.map(testmp, genboi())\n",
    "    debugs(bish[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_stats(data: Iterable):\n",
    "    histdict = {}\n",
    "    for __, targetbatch in tqdm(data, total=len(data)):\n",
    "        for cls_ in itertools.chain.from_iterable(c for c, b in targetbatch):\n",
    "            cls_ = int(cls_)\n",
    "            if cls_ not in histdict:\n",
    "                histdict[cls_] = 1\n",
    "            histdict[cls_] += 1\n",
    "    return histdict\n",
    "\n",
    "histdict = class_stats(datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    np.full((16,16), 1),\n",
    "    np.full((16,16), 2),\n",
    "    np.full((16,16), 3)\n",
    "])[None,...].repeat(10, 0).transpose((0,2,3,1))\n",
    "\n",
    "B = np.array([\n",
    "    np.full((16,16), 2),\n",
    "    np.full((16,16), 4),\n",
    "    np.full((16,16), 6)\n",
    "])[None,...].repeat(10, 0).transpose((0,2,3,1))\n",
    "\n",
    "C = np.array([\n",
    "    np.full((16,16), 3),\n",
    "    np.full((16,16), 6),\n",
    "    np.full((16,16), 9)\n",
    "])[None,...].repeat(10, 0).transpose((0,2,3,1))\n",
    "\n",
    "D = np.array([\n",
    "    np.full((16,16), 4),\n",
    "    np.full((16,16), 8),\n",
    "    np.full((16,16), 12)\n",
    "])[None,...].repeat(10, 0).transpose((0,2,3,1))\n",
    "\n",
    "E = np.array([\n",
    "    np.full((16,16), 5),\n",
    "    np.full((16,16), 10),\n",
    "    np.full((16,16), 15)\n",
    "])[None,...].repeat(10, 0).transpose((0,2,3,1))\n",
    "\n",
    "np.mean([A,B,C,D,E], (0,1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std([np.full(16*16*10, 2),\n",
    "        np.full(16*16*10, 4),\n",
    "        np.full(16*16*10, 6),\n",
    "        np.full(16*16*10, 8),\n",
    "        np.full(16*16*10, 10)\n",
    "       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std([A,B,C,D,E], (0,1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super memory efficient implementation :^)\n",
    "mean = np.zeros(3)\n",
    "denominator = 0\n",
    "for thing in [A, B, C]:\n",
    "    mean = np.average((mean, thing.mean((0,1,2))), axis=0, weights=(denominator, len(thing)))\n",
    "    denominator += len(thing)\n",
    "\n",
    "print('Mean:')\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = np.zeros_like(mean)\n",
    "denominator_var = 0\n",
    "\n",
    "for thing in [A, B, C]:    \n",
    "    m_ = ((thing-mean)**2).mean((0,1,2))\n",
    "    \n",
    "    print(var)\n",
    "    print(m_)\n",
    "    print()\n",
    "    \n",
    "    var = np.average(\n",
    "        (var, m_),\n",
    "        axis=0,\n",
    "        weights=(denominator_var, len(thing))\n",
    "    )\n",
    "    \n",
    "    denominator_var += len(thing)\n",
    "    \n",
    "print('Var: ')\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([((A - mean)**2).mean((0,1,2)), ((B - mean)**2).mean((0,1,2)), ((C - mean)**2).mean((0,1,2))]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummygen:\n",
    "    def __len__(self):\n",
    "        return 5\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return ([A,B,C,D,E][index], None)\n",
    "        \n",
    "m, v = calc_stats(Dummygen())\n",
    "print(np.sqrt(v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
