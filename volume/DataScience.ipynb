{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import torchvision.transforms as T\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from skimage import io\n",
    "\n",
    "################# DETR FUCNTIONS FOR LOSS######################## \n",
    "import sys\n",
    "sys.path.append('./detr_custom/')\n",
    "\n",
    "from models.matcher import HungarianMatcher\n",
    "from models.detr import SetCriterion\n",
    "#################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Glob\n",
    "from glob import glob\n",
    "\n",
    "from typing import Iterable, Sequence, List, Tuple, Dict, Optional, Any\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from generators import BlenderStandardDataset, Blender3DDataset\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "from utils import debugs, debug, debugt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_CACHE_DIR = 'torch_cache'\n",
    "DATASET_DIR = '/mnt/blendervol/3d_data'\n",
    "SQL_TABLE = 'bboxes_std'\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import generators\n",
    "reload(generators)\n",
    "from generators import BlenderStandardDataset\n",
    "\n",
    "datagen = Blender3DDataset(DATASET_DIR, SQL_TABLE, BATCH_SIZE, shuffle=False)\n",
    "X, y = datagen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60618"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datagen.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(data: Iterable[Tuple[np.ndarray, Any]], disable_tqdm=True):\n",
    "    denominator = 0\n",
    "    mean = np.zeros(3)\n",
    "    for imgbatch, __ in tqdm(data, total=len(data), disable=disable_tqdm):\n",
    "        n = len(imgbatch)\n",
    "        imgbatch = np.array([x[0] for x in imgbatch])\n",
    "        mean = np.average((mean, imgbatch.mean((0,1,2))), 0, weights=(denominator, n))\n",
    "        denominator += n\n",
    "        \n",
    "    return mean\n",
    "\n",
    "def calc_var(data: Iterable[Tuple[np.ndarray, Any]], mean: np.ndarray, disable_tqdm=True):\n",
    "    denominator = 0\n",
    "    var = np.zeros_like(mean)\n",
    "    for imgbatch, __ in tqdm(data, total=len(data), disable=disable_tqdm):\n",
    "        n = len(imgbatch)\n",
    "        imgbatch = np.array([x[0] for x in imgbatch])\n",
    "        batchvar = ((imgbatch - mean)**2).mean((0,1,2))\n",
    "        var = np.average((var, batchvar), axis=0, weights=(denominator, n))\n",
    "        denominator += n\n",
    "    return var\n",
    "    \n",
    "def calc_stats(data: Iterable):\n",
    "    print('Calculating mean:')\n",
    "    mean = calc_mean(data, False)\n",
    "    print('Calculating variance')\n",
    "    var = calc_var(data, mean, False)\n",
    "    print(f'Mean: {mean}')\n",
    "    print(f'Variance: {var}')\n",
    "    print(f'Std: {np.sqrt(var)}')\n",
    "    \n",
    "    return mean, var\n",
    "\n",
    "# m, v = calc_stats(datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating mean:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca950737beb40ec95cb1e425c8d332d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1894.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating variance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20f8798fdc24e348adac14e188c6f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1894.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean: [0.65629897 0.76457309 0.43896555]\n",
      "Variance: [0.00418913 0.00505205 0.00331689]\n",
      "Std: [0.06472352 0.07107777 0.05759248]\n"
     ]
    }
   ],
   "source": [
    "def _mp_calc_mean(rng: Tuple[int, int]):\n",
    "    TORCH_CACHE_DIR = 'torch_cache'\n",
    "    DATASET_DIR = '/mnt/blendervol/3d_data'\n",
    "    SQL_TABLE = 'bboxes_std'\n",
    "    BATCH_SIZE = 32\n",
    "    datagen = Blender3DDataset(DATASET_DIR, SQL_TABLE, BATCH_SIZE, shuffle=False, imgnrs=range(*rng))\n",
    "    return calc_mean(datagen)\n",
    "\n",
    "\n",
    "def _mp_calc_var(arg: Tuple[np.ndarray, Tuple[int, int]]):\n",
    "    mean, rng = arg\n",
    "    TORCH_CACHE_DIR = 'torch_cache'\n",
    "    DATASET_DIR = '/mnt/blendervol/3d_data'\n",
    "    SQL_TABLE = 'bboxes_std'\n",
    "    BATCH_SIZE = 32\n",
    "    datagen = Blender3DDataset(DATASET_DIR, SQL_TABLE, BATCH_SIZE, shuffle=False, imgnrs=range(*rng))\n",
    "    return calc_var(datagen, mean)\n",
    "\n",
    "\n",
    "def calc_mean_mp(data: Iterable):\n",
    "    with mp.Pool(20) as pool:\n",
    "        ranges = ((BATCH_SIZE*i, BATCH_SIZE*(i+1)) for i in range(len(data)))\n",
    "        pgen = pool.imap_unordered(_mp_calc_mean, ranges, chunksize=20)\n",
    "        means = tuple(tqdm(pgen, total=len(data)))\n",
    "    return np.mean(means, axis=0)\n",
    "    \n",
    "    \n",
    "def calc_var_mp(data: Iterable, mean):\n",
    "    with mp.Pool(20) as pool:\n",
    "        args = ((mean, (BATCH_SIZE*i, BATCH_SIZE*(i+1))) for i in range(len(data)))\n",
    "        pgen = pool.imap_unordered(_mp_calc_var, args, chunksize=20)\n",
    "        vars_ = tuple(tqdm(pgen, total=len(data)))\n",
    "    return np.mean(vars_, axis=0)\n",
    "    \n",
    "    \n",
    "def calc_stats_mp(data: Iterable):\n",
    "    print('Calculating mean:')\n",
    "    mean = calc_mean_mp(data)\n",
    "    print('Calculating variance')\n",
    "    var = calc_var_mp(data, mean)\n",
    "    print(f'Mean: {mean}')\n",
    "    print(f'Variance: {var}')\n",
    "    print(f'Std: {np.sqrt(var)}')\n",
    "    \n",
    "    return mean, var\n",
    "\n",
    "m_mp, v_mp = calc_stats_mp(datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stats(n, mean, var):\n",
    "    with open(\"dataset_stats.txt\", \"w+\") as f:\n",
    "        f.write(\n",
    "            f\"mean: {mean}\\n\"\n",
    "            f\"var: {var}\\n\"\n",
    "            f\"std: {np.sqrt(var)}\\n\"\n",
    "            f\"n_datapoints: {n}\\n\"\n",
    "        )\n",
    "        \n",
    "save_stats(len(datagen.indices), m_mp, v_mp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "93*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_stats(data: Iterable):\n",
    "    return pd.read_sql(\"\"\"\n",
    "        SELECT class_, COUNT(*) FROM bboxes_std \n",
    "        WHERE imgnr <= 2976\n",
    "        GROUP BY class_ \n",
    "    \"\"\", data.con)\n",
    "\n",
    "histdict = class_stats(datagen)\n",
    "histdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    np.full((16,16), 1),\n",
    "    np.full((16,16), 2),\n",
    "    np.full((16,16), 3)\n",
    "])[None,...].repeat(10, 0).transpose((0,2,3,1))\n",
    "\n",
    "B = np.array([\n",
    "    np.full((16,16), 2),\n",
    "    np.full((16,16), 4),\n",
    "    np.full((16,16), 6)\n",
    "])[None,...].repeat(10, 0).transpose((0,2,3,1))\n",
    "\n",
    "C = np.array([\n",
    "    np.full((16,16), 3),\n",
    "    np.full((16,16), 6),\n",
    "    np.full((16,16), 9)\n",
    "])[None,...].repeat(10, 0).transpose((0,2,3,1))\n",
    "\n",
    "D = np.array([\n",
    "    np.full((16,16), 4),\n",
    "    np.full((16,16), 8),\n",
    "    np.full((16,16), 12)\n",
    "])[None,...].repeat(10, 0).transpose((0,2,3,1))\n",
    "\n",
    "E = np.array([\n",
    "    np.full((16,16), 5),\n",
    "    np.full((16,16), 10),\n",
    "    np.full((16,16), 15)\n",
    "])[None,...].repeat(10, 0).transpose((0,2,3,1))\n",
    "\n",
    "np.mean([A,B,C,D,E], (0,1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std([np.full(16*16*10, 2),\n",
    "        np.full(16*16*10, 4),\n",
    "        np.full(16*16*10, 6),\n",
    "        np.full(16*16*10, 8),\n",
    "        np.full(16*16*10, 10)\n",
    "       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std([A,B,C,D,E], (0,1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super memory efficient implementation :^)\n",
    "mean = np.zeros(3)\n",
    "denominator = 0\n",
    "for thing in [A, B, C]:\n",
    "    mean = np.average((mean, thing.mean((0,1,2))), axis=0, weights=(denominator, len(thing)))\n",
    "    denominator += len(thing)\n",
    "\n",
    "print('Mean:')\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = np.zeros_like(mean)\n",
    "denominator_var = 0\n",
    "\n",
    "for thing in [A, B, C]:    \n",
    "    m_ = ((thing-mean)**2).mean((0,1,2))\n",
    "    \n",
    "    print(var)\n",
    "    print(m_)\n",
    "    print()\n",
    "    \n",
    "    var = np.average(\n",
    "        (var, m_),\n",
    "        axis=0,\n",
    "        weights=(denominator_var, len(thing))\n",
    "    )\n",
    "    \n",
    "    denominator_var += len(thing)\n",
    "    \n",
    "print('Var: ')\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([((A - mean)**2).mean((0,1,2)), ((B - mean)**2).mean((0,1,2)), ((C - mean)**2).mean((0,1,2))]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummygen:\n",
    "    def __len__(self):\n",
    "        return 5\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return ([A,B,C,D,E][index], None)\n",
    "        \n",
    "m, v = calc_stats(Dummygen())\n",
    "print(np.sqrt(v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
