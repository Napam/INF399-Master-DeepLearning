{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from typing import Iterable\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pytorch_init():\n",
    "    device_id = 1\n",
    "    torch.cuda.set_device(device_id)\n",
    "    \n",
    "    # Sanity checks\n",
    "    assert torch.cuda.current_device() == 1, 'Using wrong GPU'\n",
    "    assert torch.cuda.device_count() == 2, 'Cannot find both GPUs'\n",
    "    assert torch.cuda.get_device_name(0) == 'GeForce RTX 2080 Ti', 'Wrong GPU name'\n",
    "    assert torch.cuda.is_available() == True, 'GPU not available'\n",
    "    return torch.device('cuda', device_id)\n",
    "    \n",
    "device = pytorch_init()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main building blocks of PyTorch\n",
    "- Module\n",
    "- Sequential\n",
    "- ModuleList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module \n",
    "The Module is the main building block, it defines the base class for all neural networks and you **MUST** subclass it. Below we make a simple CNN classifier with an encoding part that uses two layers with $3 \\times 3$ convs + batchnorm + ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, in_c: int, n_classes: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_c, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=32*28*28, out_features=1024)\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1) # Flatten, .size(0) is same as .shape[0]\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNNClassifier(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyCNNClassifier(1, 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem is that it is not that scalable\n",
    "If we want to add a layer we have to declare and initialize another layer, then code what to do with it in the forward method. Also if we have some common block that we want to use in another model, we have to write it all over again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential\n",
    "Sequential is a container of Moules that can be stacked togeter and run at the same time. It very similar to Keras' sequential API. It can often yield cleaner code if used correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, in_c: int, n_classes: int):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLu()\n",
    "        )\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLu()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32 * 28 * 28, 1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024, n_classed)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythonic simplification\n",
    "We can see that some come above is quite repetetive (conv_block). We can further generalize the such that we get even more scalable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_f: int, out_f: int, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
    "        nn.BatchNorm2d(in_f, out_f),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, in_c: int, n_classes: int):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = conv_block(in_c, 32, kernel_size=3, padding=1)\n",
    "        self.conv_block2 = conv_block(32, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32 * 28 * 28, 1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNNClassifier(\n",
      "  (conv_block1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(1, eps=32, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv_block2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=64, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyCNNClassifier(1, 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even further Pythonic simplification!\n",
    "Recall that all neural network stuff subclasses nn.Module (meaning nn.Sequential is a type of nn.Module), we can use nn.Sequential inside nn.Sequential!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_f: int, out_f: int, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
    "        nn.BatchNorm2d(in_f, out_f),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, in_c: int, n_classes: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            conv_block(in_c, 32, kernel_size=3, padding=1),\n",
    "            conv_block(32, 64, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32 * 28 * 28, 1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNNClassifier(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(1, eps=32, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=64, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyCNNClassifier(1, 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic layers!\n",
    "Since everything is so Pythonic, you can very easily do Python tricks to make things more dynamic and scalable. We can simply pass the desired size of the network with a constructor parameter 8=====D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_f: int, out_f: int, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
    "        nn.BatchNorm2d(in_f, out_f),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, in_c: int, enc_sizes: Iterable[int], n_classes: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.enc_sizes = [in_c, *enc_sizes]\n",
    "        \n",
    "        conv_blocks = [conv_block(in_f, out_f, kernel_size=3, padding=1) \n",
    "                       for in_f, out_f in zip(self.enc_sizes, self.enc_sizes[1:])]\n",
    "        \n",
    "        self.encoder = nn.Sequential(*conv_blocks)\n",
    "        \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32 * 28 * 28, 1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNNClassifier(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(1, eps=32, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=64, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=128, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyCNNClassifier(1, [32, 64, 128], 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring and generalizing decoder\n",
    "At this point we have worked the encoder part, the idea works for the decoder part as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_f: int, out_f: int, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
    "        nn.BatchNorm2d(in_f, out_f),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "\n",
    "def dec_block(in_f: int, out_f: int):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_f, out_f),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "\n",
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, in_c: int, enc_sizes: Iterable[int], dec_sizes: Iterable[int],\n",
    "                 n_classes: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.enc_sizes = [in_c, *enc_sizes]\n",
    "        self.dec_sizes = [32 * 28 * 28, *dec_sizes]\n",
    "        \n",
    "        conv_blocks = [conv_block(in_f, out_f, kernel_size=3, padding=1) \n",
    "                       for in_f, out_f in zip(self.enc_sizes, self.enc_sizes[1:])]\n",
    "        \n",
    "        self.encoder = nn.Sequential(*conv_blocks)\n",
    "        \n",
    "        \n",
    "        dec_blocks = [dec_block(in_f, out_f) \n",
    "                      for in_f, out_f in zip(self.dec_sizes, self.dec_sizes[1:])]\n",
    "        self.decoder = nn.Sequential(*dec_blocks)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNNClassifier(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(1, eps=32, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=64, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyCNNClassifier(1, [32, 64], [1024, 512], 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just make the encoder and decoder their own nn.Modules!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_f: int, out_f: int, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
    "        nn.BatchNorm2d(in_f, out_f),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "\n",
    "def dec_block(in_f: int, out_f: int):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_f, out_f),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "\n",
    "class MyDecoder(nn.Module):\n",
    "    def __init__(self, dec_sizes: Iterable[int], n_classes: int):\n",
    "        super().__init__()\n",
    "        self.dec_blocks = nn.Sequential(*([\n",
    "            dec_block(in_f, out_f) for in_f, out_f in zip(dec_sizes, dec_sizes[1:])\n",
    "        ] + [nn.Linear(dec_sizes[-1], n_classes)]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dec_blocks(x)\n",
    "\n",
    "    \n",
    "class MyEncoder(nn.Module):\n",
    "    def __init__(self, enc_sizes: Iterable[int]):\n",
    "        super().__init__()\n",
    "        self.conv_blocks = nn.Sequential(*[\n",
    "            conv_block(in_f, out_f, kernel_size=3, padding=1) \n",
    "            for in_f, out_f in zip(enc_sizes, enc_sizes[1:])\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_blocks(x)\n",
    "    \n",
    "\n",
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, in_c: int, enc_sizes: Iterable[int], dec_sizes: Iterable[int],\n",
    "                 n_classes: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.enc_sizes = [in_c, *enc_sizes]\n",
    "        self.dec_sizes = [32 * 28 * 28, *dec_sizes]\n",
    "        \n",
    "        \n",
    "        self.encoder = MyEncoder(self.enc_sizes)\n",
    "        self.decoder = MyDecoder(self.dec_sizes, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNNClassifier(\n",
      "  (encoder): MyEncoder(\n",
      "    (conv_blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(1, eps=32, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=64, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): MyDecoder(\n",
      "    (dec_blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "      (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyCNNClassifier(1, [32, 64], [1024, 512], 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModuleList: when we need to iterate\n",
    "ModuleList allows you to store Module as a list. It can be useful when you need to iterate through layers and store/use some informations, like in U-Net.\n",
    "\n",
    "The main difference between Sequential is that ModuleList have NOT have forward method, so the inner layers are not connected. Assuming we need each output of each layer i nthe decoder we can store it by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self, sizes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(in_f, out_f) for in_f, out_f in zip(sizes, sizes[1:])\n",
    "        ])\n",
    "        self.trace = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            self.trace.append(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModule(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (1): Linear(in_features=16, out_features=32, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([4, 16])\n",
      "torch.Size([4, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModule([1,16,32])\n",
    "print(model)\n",
    "model(torch.rand((4,1)))\n",
    "[print(trace.shape) for trace in model.trace]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModuleDict: when we need to choose\n",
    "What if we want to switch to LeakyReLU in our conv_block? We can use ModuleDict to create a dictionary of Module and dynamically switch Module when we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_f: int, out_f: int, activation: str='relu', *args, **kwargs):\n",
    "    \n",
    "    activations = nn.ModuleDict([\n",
    "                ['lrelu', nn.LeakyReLU()],\n",
    "                ['relu', nn.ReLU()]\n",
    "    ])\n",
    "    \n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
    "        nn.BatchNorm2d(out_f),\n",
    "        activations[activation]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): LeakyReLU(negative_slope=0.01)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(conv_block(1, 32, 'lrelu', kernel_size=3, padding=1))\n",
    "print(conv_block(1, 32, 'relu', kernel_size=3, padding=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_f: int, out_f: int, activation: str='relu', *args, **kwargs):\n",
    "    \n",
    "    activations = nn.ModuleDict([\n",
    "                ['lrelu', nn.LeakyReLU()],\n",
    "                ['relu', nn.ReLU()]\n",
    "    ])\n",
    "    \n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_f, out_f, *args, **kwargs),\n",
    "        nn.BatchNorm2d(out_f),\n",
    "        activations[activation]\n",
    "    )\n",
    "\n",
    "\n",
    "def dec_block(in_f: int, out_f: int):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_f, out_f),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "    \n",
    "class MyEncoder(nn.Module):\n",
    "    def __init__(self, enc_sizes: Iterable[int], activation: str):\n",
    "        super().__init__()\n",
    "        self.conv_blocks = nn.Sequential(*[\n",
    "            conv_block(in_f, out_f, kernel_size=3, padding=1, activation=activation) \n",
    "            for in_f, out_f in zip(enc_sizes, enc_sizes[1:])\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_blocks(x)\n",
    "    \n",
    "    \n",
    "class MyDecoder(nn.Module):\n",
    "    def __init__(self, dec_sizes: Iterable[int], n_classes: int):\n",
    "        super().__init__()\n",
    "        self.dec_blocks = nn.Sequential(*([\n",
    "            dec_block(in_f, out_f) for in_f, out_f in zip(dec_sizes, dec_sizes[1:])\n",
    "            ] + [nn.Linear(dec_sizes[-1], n_classes)]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dec_blocks(x)\n",
    "    \n",
    "    \n",
    "class MyCNNClassifier(nn.Module):\n",
    "    def __init__(self, in_c: int, enc_sizes: Iterable[int], dec_sizes: Iterable[int],\n",
    "                 n_classes: int, activation: str):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.enc_sizes = [in_c, *enc_sizes]\n",
    "        self.dec_sizes = [32 * 28 * 28, *dec_sizes]\n",
    "        \n",
    "        self.encoder = MyEncoder(self.enc_sizes, activation=activation)\n",
    "        self.decoder = MyDecoder(self.dec_sizes, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNNClassifier(\n",
      "  (encoder): MyEncoder(\n",
      "    (conv_blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): MyDecoder(\n",
      "    (dec_blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "      (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyCNNClassifier(3, [32,64], [1024, 512], 10, activation='lrelu')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
